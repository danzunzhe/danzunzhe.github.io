<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>first-blog | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="4.17周报文献阅读概述神经网络底层通过推理引擎构建算子并加速并行计算的效率,，目前主流框架的缺点主要包括：  模型兼容性：Tensorflow,Pytorch,Caffe,CNTK,MXNet等模型和算子间不兼容，扩展性较差。   设备兼容性：不同研究方向采用设备平台差异性较大。统计学习采用单核多线程CPU，数据挖掘平台和深度强化学习依赖多GPU、NPU、TPU分布式并行训练。硬件架构包括ARM">
<meta property="og:type" content="article">
<meta property="og:title" content="first-blog">
<meta property="og:url" content="http://example.com/2022/04/20/first-blog/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="4.17周报文献阅读概述神经网络底层通过推理引擎构建算子并加速并行计算的效率,，目前主流框架的缺点主要包括：  模型兼容性：Tensorflow,Pytorch,Caffe,CNTK,MXNet等模型和算子间不兼容，扩展性较差。   设备兼容性：不同研究方向采用设备平台差异性较大。统计学习采用单核多线程CPU，数据挖掘平台和深度强化学习依赖多GPU、NPU、TPU分布式并行训练。硬件架构包括ARM">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416153252693.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416162805360.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416163248391.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416164035072.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416165944018.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416171616139.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416172639721.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416172726657.png">
<meta property="og:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416173031136.png">
<meta property="og:image" content="e:/Master/组会/周报/Data%201.png">
<meta property="article:published_time" content="2022-04-20T08:01:41.000Z">
<meta property="article:modified_time" content="2022-04-20T08:04:53.522Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="c:/Users/72853/AppData/Roaming/Typora/typora-user-images/image-20220416153252693.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-first-blog" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/20/first-blog/" class="article-date">
  <time class="dt-published" datetime="2022-04-20T08:01:41.000Z" itemprop="datePublished">2022-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      first-blog
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="4-17周报"><a href="#4-17周报" class="headerlink" title="4.17周报"></a>4.17周报</h1><h2 id="文献阅读"><a href="#文献阅读" class="headerlink" title="文献阅读"></a>文献阅读</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><font face="宋体">神经网络底层通过推理引擎构建算子并加速并行计算的效率,，目前主流框架的缺点主要包括：</font></p>
<ul>
<li><font face="宋体">模型兼容性：</font><font face="Times New Roman">Tensorflow,Pytorch,Caffe,CNTK,MXNet</font><font face="宋体">等模型和算子间不兼容，扩展性较差。</font></li>
</ul>
<ul>
<li><font face="宋体">设备兼容性：不同研究方向采用设备平台差异性较大。统计学习采用单核多线程</font><font face="Times New Roman">CPU，</font><font face="宋体">数据挖掘平台和深度强化学习依赖多</font><font face="Times New Roman">GPU、NPU、TPU</font><font face="宋体">分布式并行训练。硬件架构包括</font><font face="Times New Roman">ARMMail</font><font face="宋体">和高通的</font><font  face = "Times New Roman">Adreno。</font><font face = "宋体">高性能计算的底层解决方案包括</font><font face="Times New Roman">OpenGL、OpenCL、Vulkan。</font><font face="宋体">不同设备和方案之间的兼容性和耦合较低。</font></li>
<li><font face="宋体">资源调度：围绕核心算法分配线程和进程，互斥锁和消息队列间的任务窃取还存在优化空间，调度优化可提升计算性能，同时降低模型时间复杂度和空间复杂度。</font></li>
</ul>
<p><font face="宋体">基于此，阿里云提出了</font><font face="Times New Roman">MNN</font><font face="宋体">架构加速引擎推理和端侧部署效率</font></p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416153252693.png" alt="image-20220416153252693"></p>
<p><font face="宋体">上图为</font><font face="Times New Roman">MNN</font><font face="宋体">的架构，分为离线和在线的部分。离线部分将模型剪枝、压缩和量化后转出</font><font face="Times New Roman">mnn</font><font face="宋体">文件。在线推理分为：预推理，</font><font face="Times New Roman">kernel</font></p>
<p><font face="宋体">优化和后端抽象。每个算子做推理时结合多算子和后端信息做成本评估，从方案池中找出最优方案。针对每个方案进行</font><font face="Times New Roman">kernet</font></p>
<p><font face="宋体">级别的优化。加入</font><font face="Times New Roman">SIMD</font><font face="宋体">。后端抽象后就可以支持各类后端。</font></p>
<h3 id="预推理"><a href="#预推理" class="headerlink" title="预推理"></a>预推理</h3><p><font face="宋体">计算方案选择：成本评估机制：</font><br>$$<br>C_{total}&#x3D;C_{algorithm}+C_{backend}<br>$$<br>$C$<font face="宋体">表示成本。</font></p>
<ul>
<li><p>确定$C_{algorithm}$:<font face="宋体">以卷积为例，有滑窗和</font><font face="Times New Roman">Winograd</font><font face="宋体">两种实现可选，根据不同的卷积动态选最小化成本计算方法</font></p>
<ul>
<li><p>$k&#x3D;1$,<font face="宋体">直接使用</font><font face="Times New Roman">Strassen</font><font face="宋体">算法</font></p>
</li>
<li><p><font face="宋体">如果</font>$k&gt;1$<font face="宋体">则使用</font><font face="Times New Roman">Winograd</font><font face="宋体">将卷积转换为矩阵乘法，选取最小化的成本</font>$C$。<br>$$<br>C(n)&#x3D;2i_{c}(n+k-1)^{3}+i_{c}o_{c}(n+k-1)^{2}+n(n+k-1)(2n+k-1)<br>$$</p>
<p>$$<br>\hat{n}&#x3D;\mathop{\arg\min}\limits_{n}C(n)<br>$$</p>
</li>
</ul>
</li>
<li><p><font face="宋体">确定</font>$C_{backend}$:<font face="宋体">把不同后端的所有算子时间相加选取最小值</font><br>$$<br>C_{backend}&#x3D;\sum_{op}C_{op}<br>$$<br><font face="宋体">不同后端的</font>$C_{op}$<font face="宋体">差别较大，通过比较</font><font face="Times New Roman">MUL、FLOPS</font><font face="宋体">运算性能计算不同后端</font>$C_{op}$</p>
<div align=center><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416162805360.png" width="300"></div>

<p><font face="宋体">上表为一个方案性能对比，本文的方法在不同卷积参数下均为最优。</font></p>
<p><font face="宋体">下一步进行解耦，暴力开辟内存池存放推理参数，节省了频繁开辟和释放内存的过程。如下图所示：</font></p>
<div align=center><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416163248391.png" width="700"></div>

<p><font face="宋体">下表为推理时间优化结果</font></p>
</li>
</ul>
<div align=center><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416164035072.png" width="300"></div>

<h3 id="Kernel优化"><a href="#Kernel优化" class="headerlink" title="Kernel优化"></a>Kernel优化</h3><p><font face="宋体">该部分包含算法优化和调度优化，目标是优化算法和调度的复杂度，主要包含两个优化过程。z</font></p>
<ul>
<li><p><font face="Times New Roman">Winograd</font><font face="宋体">优化</font><br>$$<br>Y&#x3D;A^{T}[\sum_{channel}(GWG^{T})\bigodot(B^{T}XB)]A<br>$$<br>$G、B、A$<font face="宋体">分别为尺寸</font>$k\times k$<font face="宋体">的</font><font face="Times New Roman">kernel</font>$W$。$X$<font face="宋体">为输入，</font>$Y$<font face="宋体">为输出。</font><font face="Times New Roman">MMN</font><font face="宋体">则提出用</font><font face="Times New Roman">pipline、SIMD</font><font face="宋体">进行优化。</font></p>
<p><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416165944018.png" alt="image-20220416165944018"></p>
<p>$X$<font face="宋体">是一小块，进行块划分。</font><font face="Times New Roman">MMN</font><font face="宋体">从输出进行切分。对于输出大小</font>$[o_{w},o_{h},o_{c}]$,<font face="宋体">设</font>$T$<font face="宋体">是并行计算数，则</font>$T&#x3D;[\frac{o_{w}o_{h}}{\hat{n^{2}}}]$。</p>
<p><font face="宋体">哈达玛积是</font><font face="Times New Roman">Winofrad</font><font face="宋体">的核心，但是该运算方式访存效率低。通过研究公式发现可以将哈达玛积转换为点积并且拼接为矩阵乘法将哈达玛积转换为基于数据重新布局的矩阵乘法。用了</font><font face="Times New Roman">NC4WH4</font><font face="宋体">的数据排布，将</font>$V&#x3D;4$<font face="宋体">个数据元素拆分为一个单元来为</font><font face="Times New Roman">tensor</font><font face="宋体">增加了一个新的维度。</font><font face="Times New Roman">V</font><font face="宋体">个元素在内存中是连续排布的。利用</font><font face="Times New Roman">SIMD</font><font face="宋体">计算</font><font face="Times New Roman">M</font><font face="宋体">个数据。数据重新进行桶排序和堆排序后的卷积如上图所示。</font></p>
</li>
<li><p><font face="宋体">大矩阵承优化</font></p>
<p><font face="宋体">核心思想：加饭替换乘法进行递归运算加速引擎推理。下表和普通矩阵乘法对比。</font></p>
<div align=center><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416171616139.png" width="300"></div></li>
</ul>
<h3 id="后端抽象"><a href="#后端抽象" class="headerlink" title="后端抽象"></a>后端抽象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">lass XPUBackend <span class="keyword">final</span> : <span class="keyword">public</span> Backend &#123;</span><br><span class="line">    <span class="built_in">XPUBackend</span>(MNNForwardType type, MemoryMode mode);</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">XPUBackend</span>();</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> Execution* <span class="title">onCreate</span><span class="params">(<span class="type">const</span> vector&lt;Tensor*&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">    	<span class="type">const</span> vector&lt;Tensor*&gt;&amp; outputs, <span class="type">const</span> MNN::Op* op)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">onExecuteBegin</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">onExecuteEnd</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">onAcquireBuffer</span><span class="params">(<span class="type">const</span> Tensor* tensor, StorageType storageType)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">onReleaseBuffer</span><span class="params">(<span class="type">const</span> Tensor* tensor, StorageType storageType)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">onClearBuffer</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">onCopyBuffer</span><span class="params">(<span class="type">const</span> Tensor* srcTensor, <span class="type">const</span> Tensor* dstTensor)</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><font face="宋体">利用C++虚函数和模板重载的多泛型实现。该模块的优点为</font></p>
<ul>
<li><p><font face="宋体">降低复杂度，开辟</font><font face="Times New Roman">Backend</font><font face="宋体">类进行内存统一资源管理和分配。</font></p>
</li>
<li><p><font face="宋体">混合调度：卷积核可以同时被</font><font face="Times New Roman">CPU、GPU</font><font face="宋体">上执行。</font></p>
</li>
</ul>
<h3 id="结果对比"><a href="#结果对比" class="headerlink" title="结果对比"></a>结果对比</h3><p><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416172639721.png" alt="image-20220416172639721"></p>
<p><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416172726657.png" alt="image-20220416172726657"></p>
<p><font face="宋体">为了压榨性能，结果采用移动端部署计算模型。上图为CPU对比。第一行为2线程，第二行为4线程。</font></p>
<p><img src="C:\Users\72853\AppData\Roaming\Typora\typora-user-images\image-20220416173031136.png" alt="image-20220416173031136"></p>
<p><font face="Times New Roman">GPU</font><font face="宋体">上</font><font face="Times New Roman">MNN</font><font face="宋体">的性能显著提升，远超其他推理引擎。</font></p>
<h2 id="论文复现"><a href="#论文复现" class="headerlink" title="论文复现"></a>论文复现</h2><div align=center><img src="E:\Master\组会\周报\Data 1.png" width="400"></div>

<p><font face="宋体">机器学习库采用</font><font face="Times New Roman">Pytorch。</font><font face="宋体">采用</font><font face="Times New Roman">MNN</font><font face="宋体">和</font><font face="Times New Roman">TensorRT</font><font face="宋体">作为引擎搭载框架进行推理。</font><font face="宋体">对比结果如上图。测试平台为</font><font face="Times New Roman">GTX1050。</font><font face="宋体">对比发现基于</font><font face="Times New Roman">GPU</font><font face="宋体">的加速推理</font><font face="Times New Roman">MNN</font><font face="宋体">推理引擎具有明显优势。</font></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/04/20/first-blog/" data-id="cl27b1fm60001tgvh29vp4a1u" data-title="first-blog" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/04/20/test-my-site/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">test_my_site</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/04/20/first-blog/">first-blog</a>
          </li>
        
          <li>
            <a href="/2022/04/20/test-my-site/">test_my_site</a>
          </li>
        
          <li>
            <a href="/2022/04/20/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>